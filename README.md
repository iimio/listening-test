稲福孝信 / Listening Test
============

このREADMEはオープン以後も適宜更新される可能性があります。

現在v1.0.0のリビジョンを展示の導入文・概要文として会場にも置いてあります。

---

- 会期：2017.2.24（金）- 3.11 (土) / 火-金 [11:00-19:00] / 土 [11:00-17:00] / 日・祝・月休廊
- 会場：[ギャラリー SOBO](http://sobo.tokyo/) / [〒101-0054 東京都千代田区神田錦町3-20 アイゼンビル 3F](https://goo.gl/maps/JoMLh2EuUd52)

- 現在の作家在廊予定日時：詳細な時間は不確定ですが今の所下記の日時をのぞいて基本的に在廊予定です。

  - 2/25(土) 12時以降不在


- 25日にほとんど在廊できなさそうなのでフォローを。

    作家の惰性もありますが、作品の特性上オープン直後に見に行っても微妙な反応になるかもしれません。

    どちらにしろ基本的にはソフトウェアシンセがうにゃうにゃ言っているだけなのですが、ここ2・3日はのびしろありそうなパラメーターの精査やマッピング方法を探ったりでちょっとブレがある感じになりそう、というのと、個人的な勘（希望的観測ともいう）ですが逆にデータがある程度たまって安定してしまっても面白くなさそうな気がしていて、会期中盤ごろに見に来るのがおすすめです。

    もちろんデータセットとして何度来ていただいても歓迎します。

    最初に見にきてそもそも興味持てそうか判断＆（大々的な変化が必ずしもあるとは限りませんが）気になったら終盤もう一度覗きにくるなどでも。

    ご来廊お待ちしております。

---


## 導入と概要

この展示及び作品は大雑把に言って、会場に設置されたモノフォニックシンセサイザーとしての機能を持った２台のコンピューターが自発的・対話的に、あるいは周囲の音に反応して勝手に発音・演奏を行うインスタレーションです。

各々のコンピューターにはスピーカーとマイクがそれぞれ接続されてあり、「声のような音」として認識されたものを中心に適宜集音・解析しデータを蓄積していくことで、自身の音響合成とコンポジションを変化させていきます。

（＊注：現状では実際にオーディオファイルとして録音・保存しているわけではなく、特徴量をある程度リアルタイムに解析することで簡易的なエフェクトを与えつつ、ログデータとして記録しています、会場内で喋った内容が残るというようなことは現時点ではありません。）

２台のコンピューターは、機械学習で用いられるような統計的・確率的なネットワーク構造やデータモデルを一部に流用していますが、展示開始時の状態では、スピーチシンセサイザーのような人の声を模すことを目的としたようなものは特に意識せず、作家がある程度恣意的にベースとなるモデルを選択して音をセットアップしてあります。

外部の人の声やその他の環境音・ノイズの特徴を蓄積し、チューニングされていく先でどのような音の生成が行われるようになるのか・なるべきなのか・したいのか、実際のところ作家もよくわかっていません。

例えばひとつの方向性としては、「中間言語」と呼ばれるような種類の言語のための音響生成装置が組み上がることを少しだけ期待していたりします。

あくまで音響的な興味を前提としながら、言語やコミュニケーションの成り立ちについても考察しつつ発展させていければと思っています。


## 雑多なリンクとメモ

- WaveNet: A Generative Model for Raw Audio

  喃語

  - https://deepmind.com/blog/wavenet-generative-model-raw-audio/
  - https://soundcloud.com/paperkettle/wavenet-babble-test-trained-a-neural-network-to-speak-with-my-voice


- 人工言語、隠語 / スラング、特定の者にだけ理解できる言語
  - グーグルの人工知能、自ら情報の「暗号化」を学ぶ

    そういえばソフトウェアがある通信プロトコルに対応していることを「○○が話せる」と喩えたりする

    - https://arxiv.org/pdf/1610.06918v1.pdf
    - http://wired.jp/2016/11/02/google-ai-encryption/

  - スラング、投稿型辞書
    - [urban dictionary](http://www.urbandictionary.com/)


- AIによる翻訳・中間言語
  - http://jp.techcrunch.com/2016/11/23/20161122googles-ai-translation-tool-seems-to-have-invented-its-own-secret-internal-language/
  - https://arxiv.org/pdf/1611.04558v1.pdf
  - [ウィキペディア日本版・『中間言語』の項目](https://ja.wikipedia.org/wiki/%E4%B8%AD%E9%96%93%E8%A8%80%E8%AA%9E)


- 機械学習・解析系の技術が最終的にもたらす結果よりもフローや中間状態に自分が惹かれるなと思ったものn選（まだあった気がする）
  - http://playground.tensorflow.org
  - https://vimeo.com/12774628


- 音声学、音による言語の分類・研究
  - [国際音声記号（IPA）](https://ja.wikipedia.org/wiki/%E5%9B%BD%E9%9A%9B%E9%9F%B3%E5%A3%B0%E8%A8%98%E5%8F%B7)
  - [各記号に対する音声データ](http://coelang.tufs.ac.jp/ipa/index.php)


- 聞くこと、コンポジション

  「楽器を選ぶこと、配置を決めること、録音ボタンを押すこと、その全てが作曲行為なのです。」

  - [外の音: フィールド・レコーディングの流儀](https://www.ableton.com/ja/blog/art-of-field-recording/)


- シンセサイザーの比喩

  ざっくりとだけど一応全部見た

  - [ccc-tv / Machine Dreams, 29:00あたりくらいから](https://media.ccc.de/v/33c3-8369-machine_dreams)


- （割と直接的に）刺激を受けた作品とか

    - Rashad Becker / Traditional Music of Notional Species Vol. I / II
      - [ele-king review（Traditional Music of Notional Species Vol. II）](http://www.ele-king.net/review/album/005497/)


## 謝辞

__企画 / web / グラフィック及びテキスト監修__

竹田大純 [@thirozumi](https://github.com/thirozumi/)

__会場制作・広報等 / SOBO常駐スタッフ__

いしいこうた [@11111ECE](https://twitter.com/11111ece)
